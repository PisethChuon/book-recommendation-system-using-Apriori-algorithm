{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaaee964-06b7-4a96-9713-5e0a444bc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07815546-438e-4156-b723-1e8c584ad254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/int3072/Desktop/Python/apriori/data/synthetic_books_dataset.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# List of book titles\n",
    "books = [\"Harry Potter\", \"Hobbit\", \"LOTR\", \"Narnia\", \"Percy Jackson\", \n",
    "         \"Twilight\", \"Divergent\", \"Maze Runner\", \"Game of Thrones\", \"Eragon\"]\n",
    "\n",
    "# Dictionary to hold synthetic data\n",
    "data = {\"TransactionID\": [], \"Books\": []}\n",
    "\n",
    "# Generate 100 synthetic transactions\n",
    "for i in range(1, 101):  # 100 transactions\n",
    "    data[\"TransactionID\"].append(i)\n",
    "    # Select 2 to 5 random books for each transaction\n",
    "    data[\"Books\"].append(\", \".join(random.sample(books, random.randint(2, 5))))\n",
    "\n",
    "# Convert to a DataFrame\n",
    "synthetic_df = pd.DataFrame(data)\n",
    "\n",
    "# Save to a CSV file\n",
    "file_path = \"/Users/int3072/Desktop/Python/apriori/data/synthetic_books_dataset.csv\"\n",
    "synthetic_df.to_csv(file_path, index=False)\n",
    "\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0a3a83-ec52-4139-8f32-623fdc305d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "# Apriori implementation\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3856ce8c-9b3f-4ab6-bc8d-f880157baab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID                                        Books\n",
      "0              1              Eragon, LOTR, Hobbit, Divergent\n",
      "1              2  Narnia, Eragon, Harry Potter, Percy Jackson\n",
      "2              3                       Twilight, LOTR, Narnia\n",
      "3              4                    Maze Runner, Harry Potter\n",
      "4              5                          Divergent, Twilight\n"
     ]
    }
   ],
   "source": [
    "# Load the synthetic dataset\n",
    "df = pd.read_csv(\"../data/synthetic_books_dataset.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f6566a-ae16-4711-917b-6fcf5426e8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Eragon', 'LOTR', 'Hobbit', 'Divergent'], ['Narnia', 'Eragon', 'Harry Potter', 'Percy Jackson'], ['Twilight', 'LOTR', 'Narnia'], ['Maze Runner', 'Harry Potter'], ['Divergent', 'Twilight']]\n"
     ]
    }
   ],
   "source": [
    "# Split the 'Books' column into individual books\n",
    "transactions = df[\"Books\"].apply(lambda x: x.split(\", \")).tolist()\n",
    "\n",
    "# Check the first 5 transactions\n",
    "print(transactions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3fd943-b55d-4dc0-81c3-1ea789f49c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Divergent  Eragon  Game of Thrones  Harry Potter  Hobbit   LOTR  \\\n",
      "0       True    True            False         False    True   True   \n",
      "1      False    True            False          True   False  False   \n",
      "2      False   False            False         False   False   True   \n",
      "3      False   False            False          True   False  False   \n",
      "4       True   False            False         False   False  False   \n",
      "\n",
      "   Maze Runner  Narnia  Percy Jackson  Twilight  \n",
      "0        False   False          False     False  \n",
      "1        False    True           True     False  \n",
      "2        False    True          False      True  \n",
      "3         True   False          False     False  \n",
      "4        False   False          False      True  \n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding using TransactionEncoder\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Display the encoded dataframe (optional)\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517f85f6-3fce-49f3-974c-59d99b453476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   support           itemsets\n",
      "0     0.28        (Divergent)\n",
      "1     0.39           (Eragon)\n",
      "2     0.33  (Game of Thrones)\n",
      "3     0.34     (Harry Potter)\n",
      "4     0.33           (Hobbit)\n",
      "5     0.31             (LOTR)\n",
      "6     0.34      (Maze Runner)\n",
      "7     0.40           (Narnia)\n",
      "8     0.32    (Percy Jackson)\n",
      "9     0.34         (Twilight)\n"
     ]
    }
   ],
   "source": [
    "# Apply the Apriori algorithm to find frequent itemsets with min support of 0.2\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.2, use_colnames=True)\n",
    "\n",
    "# Display the frequent itemsets\n",
    "print(frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08ad7002-f923-4c4f-b5ac-f364cd0f1319",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "association_rules() missing 1 required positional argument: 'num_itemsets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate association rules with a minimum lift of 1.0\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m rules \u001b[38;5;241m=\u001b[39m \u001b[43massociation_rules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrequent_itemsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlift\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the association rules\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(rules\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mTypeError\u001b[0m: association_rules() missing 1 required positional argument: 'num_itemsets'"
     ]
    }
   ],
   "source": [
    "# Generate association rules with a minimum lift of 1.0\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Display the association rules\n",
    "print(rules.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6345cca-f1b0-4f77-aca7-81f897663ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
